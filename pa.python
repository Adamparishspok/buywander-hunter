#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import requests
import json
from datetime import datetime, timedelta, timezone
import csv
import time  # For delays to avoid rate limits

# Hypothetical endpointâ€”confirm via dev tools (e.g., Network tab while loading page)
base_url = "https://api.buywander.com/api/site/Auctions/list"  # Or /api/auctions; test and adjust

# Base request body from your data (customize as needed, e.g., change categories or sortBy)
req_body = {
    "pageNumber": 1,
    "pageSize": 48,
    "conditions": [],
    "itemTypes": None,
    "categories": ["Automotive"],
    "additionalCategories": [],
    "filter": None,
    "losing": False,
    "maxRetailPrice": None,
    "minRetailPrice": None,
    "myAuctions": False,
    "search": "",
    "sortBy": "BidsHighest",
    "storeLocationIds": ["08dd87d1-4832-58a3-00d8-6156d6200000"],  # Spokane-specific
    "watching": False,
    "winning": False
}

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Content-Type": "application/json",  # For POST with JSON body
    "Accept": "application/json"
}

def fetch_all_auctions():
    all_items = []
    page = 1
    while True:
        req_body["pageNumber"] = page
        try:
            response = requests.post(base_url, json=req_body, headers=headers)
            response.raise_for_status()
            data = response.json()
            all_items.extend(data.get("items", []))
            if not data.get("hasNextPage", False):
                break
            page += 1
            time.sleep(5)  # Delay to avoid rate limiting or blocks
        except Exception as e:
            print(f"Error on page {page}: {e}")
            break
    return all_items

def is_good_deal(item):
    # More lenient criteria to actually find some deals
    retail = item["item"].get("price", 0)
    winning_bid = item.get("winningBid")
    current_bid = winning_bid.get("amount", 0) if winning_bid else 0
    end_date_str = item.get("endDate")
    if not end_date_str or retail == 0:
        return False
    end_date = datetime.fromisoformat(end_date_str.replace("+00:00", "Z"))  # UTC to datetime
    now = datetime.now(timezone.utc)
    time_left = end_date - now
    bids = winning_bid.get("bids", 0) if winning_bid else 0

    # More reasonable criteria: bid < 70% retail, ending within 3 days, at least 1 bid
    return (current_bid < 0.7 * retail) and (time_left < timedelta(days=3)) and (bids >= 1)

def monitor_deals():
    auctions = fetch_all_auctions()
    print(f"Fetched {len(auctions)} auctions total")
    deals = [item for item in auctions if is_good_deal(item)]
    print(f"Found {len(deals)} potential deals after filtering")
    
    if deals:
        # Save to CSV for tracking
        with open('buywander_deals.csv', 'w', newline='') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['Title', 'Retail', 'Current Bid', 'End Date', 'URL'])
            for deal in deals:
                title = deal["item"].get("title", "N/A")
                retail = deal["item"].get("price", 0)
                bid = deal.get("winningBid", {}).get("amount", 0)
                end_date = deal.get("endDate", "N/A")
                url = f"https://buywander.com/auctions/{deal['id']}"  # Assuming URL pattern; adjust
                writer.writerow([title, retail, bid, end_date, url])
        
        print(f"Found {len(deals)} deals! Saved to buywander_deals.csv")
        # Add email notification here (e.g., using smtplib)
        # Example: send_email("Deals Found!", f"Found {len(deals)} Automotive deals in Spokane.")
    else:
        print("No good deals found today.")

# Run the monitor
monitor_deals()